---

# Technical Specifications: Synthetic Data Generation Engine (RAG + Taxonomies)

## Overview

This system utilizes a hybrid Retrieval-Augmented Generation (RAG) architecture.

* **Phase 1** ingests highly detailed Seed Case JSONs into ChromaDB, separating searchable semantic embeddings from exact-match metadata and full JSON payloads.
* **Phase 2** orchestrates an LLM to generate high-fidelity synthetic cases by querying ChromaDB for "Few-Shot" examples and cross-referencing three static Taxonomy JSON files (`Friction`, `Action`, `Outcome`).

## Prerequisites

* **Language:** Python 3.10+
* **Core Libraries:** `chromadb`, `pydantic`, `openai` (or equivalent LLM SDK), `json`, `os`
* **Local Storage:**
* `./data/seed_cases/` (Contains the 15 Seed Case JSONs)
* `./data/taxonomies/` (Contains `friction_taxonomy.json`, `action_taxonomy.json`, `outcome_taxonomy.json`)
* `./chroma_db/` (Persistent local vector storage)
* `./data/synthetic_output/` (Destination for generated cases)



---

## Phase 1: Seed Case Vectorization (ChromaDB Ingestion)

**Agent Goal:** Read the 15 Seed Case JSON files, parse them into vectors, metadata, and document payloads, and upsert them into a local ChromaDB collection.

### 1.1 Data Mapping Rules

ChromaDB requires `ids`, `documents` (text to embed), `metadatas` (filters), and `embeddings` (auto-generated by Chroma if not provided).

* **`ids`**: Extract from `case_header.case_id`.
* **`documents` (Semantic Search Target)**: Concatenate the narrative/logical elements into a single searchable string.
* Extract and join: `clinical_logic.clinical_barriers`, `environmental_logic.physical_barriers`, `reasoning_trace_triples` (summarized), and `unscripted_chaos_signals`.


* **`metadatas` (Hard Filters)**: ChromaDB metadata only accepts strings, ints, or floats.
* `complexity_score`: Convert to `int` (e.g., `5`).
* `outcome`: `str` (e.g., `"Service Conversion"`).
* `has_skilled_need`: `str` (e.g., `"Yes"` or `"No"` based on `clinical_logic.skilled_need_verified`).
* `primary_friction`: `str` (Extract the first item from `environmental_logic.modification_type` or similar, e.g., `"Medicaid CHC Waiver"`).


* **`payload` (Full JSON)**: To ensure the LLM gets the perfectly formatted JSON later, serialize the entire original JSON object into a string and store it as a special metadata field: `{"raw_json": json.dumps(original_data)}`.

### 1.2 Ingestion Algorithm

```python
# Pseudo-code logic for the Agent
1. Initialize chromadb.PersistentClient(path="./chroma_db")
2. Get or create collection name="seed_cases"
3. For each file in ./data/seed_cases/:
    a. Load JSON.
    b. Build `document_string` (concat reasoning + barriers).
    c. Build `metadata_dict` (complexity, outcome, has_skilled_need, primary_friction, raw_json).
    d. Append to batch lists (ids, documents, metadatas).
4. collection.upsert(ids=ids, documents=documents, metadatas=metadatas)

```

---

## Phase 2: Orchestrated Synthetic Case Generation

**Agent Goal:** Dynamically construct a prompt using the static Taxonomies and retrieved ChromaDB seed cases, call the LLM, and output a validated JSON matching the 3 approved formats.

### 2.1 Retrieval Logic (RAG Step)

Before calling the LLM, the agent must define the target parameters for the new synthetic case (e.g., target complexity: 5, target friction: "Managed Medicare Auth").

1. **Query ChromaDB:**
* Filter: `{"complexity_score": {"$gte": 4}}`
* Query Text: `"Bureaucratic delay with language barriers or scheduling chaos"`
* `n_results = 2`


2. **Extract Payloads:**
* Iterate through the `results['metadatas']`.
* Parse the `raw_json` string back into a Python dictionary. These serve as the "Few-Shot Examples".



### 2.2 LLM Prompt Assembly

The agent must construct a system/user prompt combining the following elements:

**[System Prompt]**

> "You are an AI Healthcare Architect. Your task is to generate a high-complexity Synthetic Patient Case. You must strictly adhere to the provided Static Taxonomies for mathematical delays (EDD Delta) and role boundaries. Do not hallucinate delays; use the Friction Taxonomy."

**[Context Injection 1: Static Taxonomies]**

> Load and inject the stringified JSONs from `./data/taxonomies/`.
> * Friction Taxonomy (Defines Time Delays)
> * Action Taxonomy (Defines Rank 1 Success Intents)
> * Outcome Taxonomy (Defines State Transition Triggers)
> 
> 

**[Context Injection 2: Reference Seed Cases (The DNA)]**

> "Here are two real-world seed cases. Mimic their level of clinical detail, operational chaos, and formatting exactly."
> Inject the 2 parsed JSONs retrieved from ChromaDB.

**[Task Instruction & Target Variables]**

> "Generate 1 NEW synthetic case.
> Target Variables for this run:
> * Patient: 78yo Female, CHF.
> * Main Friction: [Insert Random/Selected Friction from Taxonomy].
> Output the response strictly conforming to the Pydantic schema."
> 
> 

### 2.3 Required Output Schema (Pydantic / Structured Outputs)

To ensure the output maps perfectly to the final database, the Agent MUST enforce structured JSON output using Pydantic (or OpenAI's `response_format`).

```python
from pydantic import BaseModel, Field
from typing import List, Literal

class StateLogEntry(BaseModel):
    event_description: str
    clinical_impact: Literal["Improves", "Worsens", "Unchanged"]
    environmental_impact: Literal["Improves", "Worsens", "Unchanged"]
    service_adoption_impact: Literal["Positive", "Negative", "Unchanged"]
    edd_delta: str = Field(description="Must match Friction Taxonomy rule, e.g., '+30 Days'")

class ReasoningTriple(BaseModel):
    situation: str
    action_taken: str
    intent: str = Field(description="Must match exactly with an intent from Action Taxonomy")
    goal_met: bool

class RLChoice(BaseModel):
    rank: Literal[0, 1]
    action_type: Literal["Optimal", "Passive", "Overstep"]
    description: str
    rationale: str

class SyntheticCaseOutput(BaseModel):
    format_1_state_log: List[StateLogEntry]
    format_2_triples: List[ReasoningTriple]
    format_3_rl_scenario: List[RLChoice]
    narrative_summary: str

```

### 2.4 Output Handling

1. Validate LLM response against the `SyntheticCaseOutput` Pydantic model.
2. Save the validated output to `./data/synthetic_output/synthetic_case_[TIMESTAMP].json`.
3. Loop for the number of requested batch generations.
